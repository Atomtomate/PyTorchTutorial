{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Setup, Classifier and Convolutional Variational Autoencoders\n",
    "\n",
    "\n",
    "The model follows [this](https://bytepawn.com/building-a-pytorch-autoencoder-for-mnist-digits.html) tutorial by Bytepawn (The Blog covers interesting computer science/astro physics crossover topics).\n",
    "Visualizations ideas are taken from [this](https://skannai.medium.com/what-are-convolutional-variational-auto-encoders-cvae-515f4fedc23) blog ny Berke TÃ¼rkmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from os.path import dirname, abspath, join\n",
    "import lightning as L\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, StochasticWeightAveraging, GradientAccumulationScheduler\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch, json, sys\n",
    "from os.path import dirname, abspath, join\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "sys.path.insert(1, '03_FullSetup')\n",
    "from models import *\n",
    "from utils import *\n",
    "from data import *\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# TODO load from checkpoint\n",
    "\n",
    "config = json.load(open('03_FullSetup/config.json'))\n",
    "torch.manual_seed(config['seed']);\n",
    "\n",
    "\n",
    "# set dtype, float64 is almost never necessary\n",
    "dtype_default = torch.float32\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.set_default_dtype(dtype_default)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE2(\n",
       "  (activation): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (log_likelihood): MSELoss()\n",
       "  (encoder): ConvEncoder(\n",
       "    (activation): ReLU()\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (activation): ReLU()\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=3136, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(64, 7, 7))\n",
       "      (2): ReLU()\n",
       "      (3): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (latent_z): LatentZ(\n",
       "    (mu): Linear(in_features=3136, out_features=2, bias=True)\n",
       "    (logvar): Linear(in_features=3136, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_mode = 'inference'\n",
    "\n",
    "dataMod = CVAE_MNIST_Data(config)\n",
    "model = CVAE2(config, device, mode = 'conv') \n",
    "ckpt_path = \"lightning_logs/VAE_Classifier/version_39/checkpoints/last.ckpt\"\n",
    "device = 'cpu'\n",
    "\n",
    "if run_mode == 'inference':\n",
    "    model = CVAE2.load_from_checkpoint(ckpt_path)\n",
    "    model.eval()\n",
    "elif run_mode =='fit':\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=config[\"model_name\"])\n",
    "    val_ckeckpoint = ModelCheckpoint( # saved in `trainer.default_root_dir`/`logger.version`/`checkpoint_callback.dirpath`\n",
    "                filename=\"{epoch}-{step}-{val_loss:.8f}\",\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                save_top_k=2,\n",
    "                save_last =True\n",
    "                )\n",
    "    callbacks = [lr_monitor, val_ckeckpoint]\n",
    "    trainer = Trainer(enable_checkpointing=True, max_epochs=config[\"epochs\"],\n",
    "                        callbacks=callbacks, logger=logger)\n",
    "\n",
    "    trainer.fit(model, ckpt_path=ckpt_path)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_digit(model, device, mean=2.5, var=1.0), generate_digit(model, device, mean=1.0, var=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Maps\n",
    "\n",
    "[this](https://github.com/utkuozbulak/pytorch-cnn-visualizations) GitHub Repository provides visualization examples. Most of them are publications of themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['', 'activation', 'lossF', 'encoder', 'encoder.encoder', 'encoder.encoder.0', 'encoder.encoder.2', 'encoder.encoder.4', 'encoder.encoder.5', 'decoder', 'decoder.decoder', 'decoder.decoder.0', 'decoder.decoder.2', 'decoder.decoder.4', 'decoder.decoder.5', 'decoder.decoder.6'])\n"
     ]
    }
   ],
   "source": [
    "print(dict([*model.named_modules()]).keys())\n",
    "return_nodes = {\n",
    "    'encoder.encoder.0': 'enc_0',\n",
    "    'encoder.encoder.2': 'enc_1',\n",
    "    'encoder.encoder.4': 'enc_2',\n",
    "    'encoder.encoder.5': 'enc_3',\n",
    "    'decoder.decoder.0': 'dec_0',\n",
    "    'decoder.decoder.2': 'dec_1',\n",
    "    'decoder.decoder.4': 'dec_2',\n",
    "    'decoder.decoder.5': 'dec_3',\n",
    "    'decoder.decoder.6': 'dec_4',\n",
    "}\n",
    "fe = FeatureExtractor(model, return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (8x400 and 3200x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m dataMod\u001b[38;5;241m.\u001b[39mtrain_dataset[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Codes\\PyTorchTutorial\\03_FullSetup\\models.py:99\u001b[0m, in \u001b[0;36mCVAE2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 99\u001b[0m     mean, logvar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim , dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    100\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterization(mean, logvar)\n\u001b[0;32m    101\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(y)\n",
      "File \u001b[1;32mg:\\Codes\\PyTorchTutorial\\03_FullSetup\\models.py:88\u001b[0m, in \u001b[0;36mCVAE2.encode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 88\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m#mean, logvar = self.mean_layer(x), self.logvar_layer(x)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\Codes\\PyTorchTutorial\\03_FullSetup\\models.py:41\u001b[0m, in \u001b[0;36mConvEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1566\u001b[0m     ):\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Atomt\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (8x400 and 3200x20)"
     ]
    }
   ],
   "source": [
    "dataMod.setup('test')\n",
    "model = model.to('cpu')\n",
    "model.c_device = 'cpu'\n",
    "model.eval()\n",
    "fe = fe.to('cpu')\n",
    "fe.eval()\n",
    "x_test, y_test = dataMod.train_dataset[1]\n",
    "x_test = x_test.to('cpu')\n",
    "y_pred = model(x_test).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl = DataLoader(dataMod.test_dataset, batch_size=1, num_workers=1, persistent_workers=False, shuffle=False)\n",
    "data_it = iter(dl)\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "grid = ImageGrid(fig, 111, \n",
    "                 nrows_ncols=(3,12), \n",
    "                 axes_pad=(0.1,0.4), \n",
    "                 )\n",
    "\n",
    "im, label = next(data_it)\n",
    "for ax in grid:\n",
    "    data = next(data_it)\n",
    "    im,label =  data\n",
    "    im_fe = fe(next(data_it)).to('cpu')\n",
    "    ax.imshow(im.reshape(28,28), cmap=\"gray\")\n",
    "    ax.set_title(label.item())\n",
    "    ax.axis('off')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMod\n",
    "data_it = iter(test_loader)\n",
    "for ax in grid:\n",
    "    im, label = next(data_it)\n",
    "    ax.imshow(im.reshape(28,28), cmap=\"gray\")\n",
    "    ax.set_title(label.item())\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate New Data\n",
    "\n",
    "Variational Autoencoders are capable of generating **new** output by providing a sample for the latent distribution and feeding it to the decoder. \n",
    "\n",
    "- Latent space range\n",
    "- generate some images\n",
    "- interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "## Transfer Learning\n",
    "\n",
    "## Domain Adaptation\n",
    "\n",
    "## Specialized architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for Feature Extraction (used for transfer learning)\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
    "\n",
    "# print all layers\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)\n",
    "\n",
    "# specfy the iteresting ones\n",
    "\n",
    "\n",
    "create_feature_extractor(model, return_nodes=return_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
